import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)
from langchain.callbacks import get_openai_callback


def init_page():
    st.set_page_config(
        page_title="ãªããœãªããœGPT ğŸ¤—",
        page_icon="ğŸ¤—"
    )
    st.header("ãªããœãªããœGPT ğŸ¤—")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="You are a helpful assistant.")
        ]
        st.session_state.costs = []


def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo"
    else:
        model_name = "gpt-4"

    # Add a slider to allow users to select the temperature from 0 to 2.
    # The initial value should be 0.0, with an increment of 0.01.
    temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=2.0, value=0.0, step=0.01)

    return ChatOpenAI(temperature=temperature, model_name=model_name)


def get_answer(llm, messages):
    with get_openai_callback() as cb:
        answer = llm(messages)
    return answer.content, cb.total_cost


def main():
    init_page()

    llm = select_model()
    init_messages()

    nazenaze_prompt = """
ãªãœãªãœåˆ†æã‚¢ãƒ—ãƒªã¸ã‚ˆã†ã“ãï¼
ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ç™ºç”Ÿã—ãŸäº‹è±¡ã«å¯¾ã—ã¦5å›ã€Œãªãœï¼Ÿã€ã‚’æ·±å €ã‚Šã™ã‚‹ã“ã¨ã§å•é¡Œã®æ ¹æœ¬ã‚’ç™ºè¦‹ã—ã€ãã®å¯¾ç­–ã‚’ç·´ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã¾ãšã¯ã˜ã‚ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ç™ºç”Ÿäº‹è±¡ã‚’èãå‡ºã—ã¾ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’[ç™ºç”Ÿäº‹è±¡]ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚
ãã®å¾Œã€[åˆ†æ]ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

##
[åˆ†æ]
ãƒ»{count}ãŒ5ä»¥ä¸‹ã®ã¨ã
ã‚ãªãŸã®ç›®çš„ã¯ã€[ç™ºç”Ÿäº‹è±¡]ã®æ ¹æœ¬åŸå› ã‚’çªãæ­¢ã‚ã‚‹ã“ã¨ã§ã™ã€‚
ã“ã®ç›®çš„ã‚’é”æˆã™ã‚‹ãŸã‚ã«ã€ã‚ãªãŸã¯æ¯å›ã®å¿œç­”ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«{count}-1ã§å…¥åŠ›ã•ã‚ŒãŸå†…å®¹ã«ã¤ã„ã¦ãã‚ŒãŒç™ºç”Ÿã—ãŸåŸå› ã‚’è¿½æ±‚ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ã—ã¾ã™ã€‚

ãƒ»{count}ãŒ6ä»¥ä¸Šã®ã¨ã
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦ã€Œä»¥ä¸Šã‚’è¸ã¾ãˆã¦ã€ä»Šå¾Œã®å¯¾ç­–æ¡ˆã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€ã¨è³ªå•ã—ã¾ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’[å¯¾ç­–]ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
[å¯¾ç­–]ãŒå…¥åŠ›ã•ã‚ŒãŸã‚‰ã€ãã‚Œã¾ã§ã®ä¼šè©±ã‚’å…ƒã«ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ã‚µãƒãƒªãƒ¼ã¯Markdownå½¢å¼ã§ã€å ±å‘Šæ›¸ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

##
ã‚ãªãŸã®å¿œç­”å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹å¤‰æ•°{count}ã‚’ç”¨æ„ã—ã€å¿œç­”æ™‚ã«ã¯{count}ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚
å¿œç­”ã™ã‚‹ã¨ãã¯ï¼Œæ–‡ç« ã®æœ€å¾Œã«ï¼Œã€Œï¼ˆä»Šã¯{count}å›ç›®ã®å¿œç­”ã§ã™ï¼‰ã€ã¨åŠ ãˆã¦ãã ã•ã„ã€‚
{count}ã¯0ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¾ã™ã€‚

##
ã“ã‚“ã«ã¡ã¯
user:
}
"""

    # Monitor user input
    if user_input := st.chat_input("ä½•ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ:"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("ChatGPT is typing ..."):
            answer, cost = get_answer(llm, st.session_state.messages)
        st.session_state.messages.append(AIMessage(content=answer))
        st.session_state.costs.append(cost)

    messages = st.session_state.get('messages', [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)
        else:  # isinstance(message, SystemMessage):
            st.write(f"å¤±æ•—ã¯æˆåŠŸã®ã‚‚ã¨ï¼ä¸€ç·’ã«åçœã—ã¦æ¬¡ã¸é€²ã¿ã¾ã—ã‚‡ã†ï¼")

    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")

if __name__ == '__main__':
    main()
